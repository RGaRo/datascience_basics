{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1f5c45",
   "metadata": {},
   "source": [
    "# **Inside Logistic Regression: A Step-by-Step Guide with Titanic as a Case Study**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db362e0",
   "metadata": {},
   "source": [
    "### **Libraries used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d142ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Literal\n",
    "\n",
    "from scratch.complex_typing import Vector\n",
    "from scratch.metrics import precision, recall, f1_score, print_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a21c9",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed98fd",
   "metadata": {},
   "source": [
    "Logistic regression is a fundamental classification algorithm widely used in statistics, machine learning, and data science. Unlike linear regression, which predicts continuous values, logistic regression estimates the probability that a given input belongs to a particular class. It serves as the foundation for more complex models such as neural networks and generalized linear models, making it an essential concept for practitioners and researchers alike.\n",
    "\n",
    "This notebook presents a complete implementation of logistic regression from scratch, focusing on the mathematical foundations and algorithmic processes that define the model. We will explore the logistic function, the log-likelihood objective, and the optimization process used to find the best parameters through gradient ascent.\n",
    "\n",
    "As a practical application, we will use the Titanic dataset — a classic and publicly available dataset — to predict passenger survival based on features such as age, class, and sex. This example offers a compelling context for exploring the real-world performance of logistic regression and demonstrates the full workflow from data preparation to model evaluation.\n",
    "\n",
    "By the end of this notebook, readers will gain a clear conceptual and practical understanding of how logistic regression works internally, how to implement it, and how to evaluate its performance using standard classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637b1e4",
   "metadata": {},
   "source": [
    "### **Theoretical framework**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc571c",
   "metadata": {},
   "source": [
    "**Logistic regression**\n",
    "\n",
    "Logistic regression is a supervised learning algorithm used for binary classification tasks. At its core, it models the probability that a sample belongs to the positive class using the logistic (sigmoid) function:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "where $z = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_n x_n$ is the linear combination of the input features and their associated parameters (coefficients). This function ensures the output values lie between 0 and 1, which makes them interpretable as probabilities.\n",
    "\n",
    "To fit the model, we aim to maximize the likelihood of observing the actual data, given the model parameters. This is commonly done by maximizing the log-likelihood function using gradient ascent. The derivative of this function with respect to each parameter (i.e., the gradient) guides the update of the parameters at each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e14e39",
   "metadata": {},
   "source": [
    "**Gradient and Gradient Ascent in Logistic Regression**\n",
    "\n",
    "*The gradient*\n",
    "\n",
    "In logistic regression, our goal is to find the best parameters (also called coefficients) that allow our model to correctly predict the probability that a given input belongs to class 1 (usually represented as y = 1).\n",
    "\n",
    "To do this, we use something called the log-likelihood function. This function tells us how likely it is that our model, with its current parameters, would have produced the actual labels in the data. The higher the likelihood, the better our model fits the data.\n",
    "\n",
    "We use the sigmoid function (explained before), denoted by $\\sigma(z)$, to convert the linear combination of inputs into a probability:\n",
    "\n",
    "*Log-Likelihood Function*\n",
    "\n",
    "For a single training example $(\\mathbf{x}_i, y_i)$, the probability of the outcome under the model is:\n",
    "\n",
    "$$\n",
    "P(y_i \\mid \\mathbf{x}_i) = \\sigma(z_i)^{y_i} (1 - \\sigma(z_i))^{1 - y_i}\n",
    "$$\n",
    "\n",
    "Taking the logarithm (to make the math easier and more stable), we get the log-likelihood for all the training examples:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^{m} \\left[ y_i \\log(\\sigma(z_i)) + (1 - y_i) \\log(1 - \\sigma(z_i)) \\right]\n",
    "$$\n",
    "\n",
    "This is the function we want to maximize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba80ba",
   "metadata": {},
   "source": [
    "*The Gradient Ascent*\n",
    "\n",
    "To maximize the log-likelihood, we use an optimization method called gradient ascent. The idea is simple: we compute the gradient (the direction in which the log-likelihood increases the fastest), and then take small steps in that direction.\n",
    "\n",
    "The formula for updating the parameters is:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\beta} \\leftarrow \\boldsymbol{\\beta} + \\eta \\cdot \\nabla \\mathcal{L}(\\boldsymbol{\\beta})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\eta$ is the learning rate (how big each step is),\n",
    "- $\\nabla \\mathcal{L}(\\boldsymbol{\\beta})$ is the gradient, a vector that tells us how much each coefficient should change.\n",
    "\n",
    "Each partial derivative in the gradient is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\beta_j} = \\sum_{i=1}^{m} \\left( y_i - \\sigma(z_i) \\right) x_{ij}\n",
    "$$\n",
    "\n",
    "In words, the update for each coefficient depends on the difference between the actual label and the predicted probability, multiplied by the value of the input feature. This tells us whether to increase or decrease the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d6d8c4",
   "metadata": {},
   "source": [
    "**Data Preparation and Preprocessing**\n",
    "\n",
    "Proper data preparation is critical for building a robust and generalizable model. One of the most important principles in machine learning is to simulate real-world prediction scenarios, where the model must generalize to unseen data. Therefore, the first step must always be to split the dataset into training and testing sets.\n",
    "\n",
    "No transformation (including imputation, encoding, or normalization) should be applied before this split. Applying transformations before splitting would lead to data leakage, where information from the test set influences the training process, resulting in overly optimistic performance estimates.\n",
    "\n",
    "Once the dataset is split, we apply the following preprocessing steps separately on each subset, ensuring that the transformations learned from the training data are reused (not re-fitted) on the test data.\n",
    "\n",
    "1. Imputation of Missing Values\n",
    "\n",
    "Real-world data often contains missing entries. These must be handled carefully to maintain the model’s integrity. We fit an imputation strategy (e.g., replacing missing values with the mean or median) on the training set only and then apply that strategy to both training and testing data. This avoids using information from the test set that would otherwise bias model evaluation.\n",
    "\n",
    "2. Encoding Categorical Variables\n",
    "\n",
    "Categorical features need to be converted to numerical format for use in logistic regression. We use one-hot encoding (i.e., dummy variables) to achieve this. As with imputation, the encoder is fit on the training data and applied identically to the test data to ensure consistency in the number and order of resulting features.\n",
    "\n",
    "3. Normalization\n",
    "\n",
    "Because logistic regression relies on gradient-based optimization, features should be on a similar scale to improve convergence and interpretability. We standardize the numerical features by removing the mean and scaling to unit variance, using statistics (mean and standard deviation) computed from the training set. These parameters are then used to transform the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee6874f",
   "metadata": {},
   "source": [
    "**Why These Steps Matter**\n",
    "\n",
    "Each transformation—imputation, encoding, and normalization—is essential for ensuring the quality and fairness of the model. More importantly, applying these transformations after splitting the data preserves the integrity of the testing process. Any leakage of information from the test set into the training phase can result in models that overfit and perform poorly on unseen data.\n",
    "\n",
    "In the next section, we will apply this pipeline while implementing logistic regression from scratch using the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e233325",
   "metadata": {},
   "source": [
    "### **Practical example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526ac1e",
   "metadata": {},
   "source": [
    "To begin our practical implementation, we first need to load the dataset. In this case, we will use the famous Titanic dataset, which contains information about the passengers aboard the Titanic, including features such as age, sex, ticket class, and whether or not they survived. This dataset is commonly used for binary classification tasks, making it an ideal candidate for our logistic regression model.\n",
    "\n",
    "We will load the dataset using pandas, which provides a simple and efficient way to handle structured data in Python. Once loaded, we will take a quick look at the structure of the dataset to better understand the features and identify any preprocessing steps that may be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fb1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('datasets/titanic_dataset.csv')\n",
    "df_adjusted = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86536e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    \"\"\"\n",
    "    Prints a detailed summary of each column in a pandas DataFrame.\n",
    "    Shows type, missing values, and descriptive statistics for each column.\n",
    "    \"\"\"\n",
    "    print(f\"\\nDataFrame Summary: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for col in df.columns:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"Type: {df[col].dtype}\")\n",
    "        print(f\"Missing values: {df[col].isna().sum()}\")\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            print(f\"Mean: {df[col].mean():.5f}\")\n",
    "            print(f\"Median: {df[col].median():.5f}\")\n",
    "            print(f\"Min: {df[col].min():.5f}\")\n",
    "            print(f\"Max: {df[col].max():.5f}\")\n",
    "            print(f\"Standard Deviation: {df[col].std():.5f}\")\n",
    "        elif pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            print(\"Value counts:\")\n",
    "            print(df[col].value_counts())\n",
    "        elif pd.api.types.is_bool_dtype(df[col]):\n",
    "            print(\"Value counts:\")\n",
    "            print(df[col].value_counts())\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            print(f\"Min date: {df[col].min():.5f}\")\n",
    "            print(f\"Max date: {df[col].max():.5f}\")\n",
    "        else:\n",
    "            print(\"Unrecognized or complex data type.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\nEnd of summary.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee87e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Summary: 891 rows, 12 columns\n",
      "============================================================\n",
      "\n",
      "Column: PassengerId\n",
      "Type: int64\n",
      "Missing values: 0\n",
      "Mean: 446.00000\n",
      "Median: 446.00000\n",
      "Min: 1.00000\n",
      "Max: 891.00000\n",
      "Standard Deviation: 257.35384\n",
      "\n",
      "Column: Survived\n",
      "Type: int64\n",
      "Missing values: 0\n",
      "Mean: 0.38384\n",
      "Median: 0.00000\n",
      "Min: 0.00000\n",
      "Max: 1.00000\n",
      "Standard Deviation: 0.48659\n",
      "\n",
      "Column: Pclass\n",
      "Type: int64\n",
      "Missing values: 0\n",
      "Mean: 2.30864\n",
      "Median: 3.00000\n",
      "Min: 1.00000\n",
      "Max: 3.00000\n",
      "Standard Deviation: 0.83607\n",
      "\n",
      "Column: Name\n",
      "Type: object\n",
      "Missing values: 0\n",
      "Value counts:\n",
      "Name\n",
      "Braund, Mr. Owen Harris                     1\n",
      "Boulos, Mr. Hanna                           1\n",
      "Frolicher-Stehli, Mr. Maxmillian            1\n",
      "Gilinski, Mr. Eliezer                       1\n",
      "Murdlin, Mr. Joseph                         1\n",
      "                                           ..\n",
      "Kelly, Miss. Anna Katherine \"Annie Kate\"    1\n",
      "McCoy, Mr. Bernard                          1\n",
      "Johnson, Mr. William Cahoone Jr             1\n",
      "Keane, Miss. Nora A                         1\n",
      "Dooley, Mr. Patrick                         1\n",
      "Name: count, Length: 891, dtype: int64\n",
      "\n",
      "Column: Sex\n",
      "Type: object\n",
      "Missing values: 0\n",
      "Value counts:\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: Age\n",
      "Type: float64\n",
      "Missing values: 177\n",
      "Mean: 29.69912\n",
      "Median: 28.00000\n",
      "Min: 0.42000\n",
      "Max: 80.00000\n",
      "Standard Deviation: 14.52650\n",
      "\n",
      "Column: SibSp\n",
      "Type: int64\n",
      "Missing values: 0\n",
      "Mean: 0.52301\n",
      "Median: 0.00000\n",
      "Min: 0.00000\n",
      "Max: 8.00000\n",
      "Standard Deviation: 1.10274\n",
      "\n",
      "Column: Parch\n",
      "Type: int64\n",
      "Missing values: 0\n",
      "Mean: 0.38159\n",
      "Median: 0.00000\n",
      "Min: 0.00000\n",
      "Max: 6.00000\n",
      "Standard Deviation: 0.80606\n",
      "\n",
      "Column: Ticket\n",
      "Type: object\n",
      "Missing values: 0\n",
      "Value counts:\n",
      "Ticket\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "CA 2144     6\n",
      "           ..\n",
      "9234        1\n",
      "19988       1\n",
      "2693        1\n",
      "PC 17612    1\n",
      "370376      1\n",
      "Name: count, Length: 681, dtype: int64\n",
      "\n",
      "Column: Fare\n",
      "Type: float64\n",
      "Missing values: 0\n",
      "Mean: 32.20421\n",
      "Median: 14.45420\n",
      "Min: 0.00000\n",
      "Max: 512.32920\n",
      "Standard Deviation: 49.69343\n",
      "\n",
      "Column: Cabin\n",
      "Type: object\n",
      "Missing values: 687\n",
      "Unrecognized or complex data type.\n",
      "\n",
      "Column: Embarked\n",
      "Type: object\n",
      "Missing values: 2\n",
      "Unrecognized or complex data type.\n",
      "\n",
      "============================================================\n",
      "End of summary.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/z7k3sy6x0l555p2rqjf6zvtr0000gn/T/ipykernel_16011/604072689.py:20: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_categorical_dtype(df[col]):\n"
     ]
    }
   ],
   "source": [
    "summary(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae85a5d",
   "metadata": {},
   "source": [
    "The Titanic dataset consists of 891 passenger records and 12 columns, capturing a mix of numerical and categorical features. The target variable is Survived, a binary indicator of whether a passenger survived (1) or not (0), with a survival rate of approximately 38% in the dataset.\n",
    "\n",
    "Among the numerical variables, we find:\n",
    "\t•\tAge, which ranges from 0.42 to 80 years but contains 177 missing values.\n",
    "\t•\tFare, ranging from 0 to 512.33, shows high variance.\n",
    "\t•\tSibSp and Parch represent family relations aboard and have skewed distributions toward lower values.\n",
    "\n",
    "The categorical features include:\n",
    "\t•\tSex, with a distribution of 577 males and 314 females.\n",
    "\t•\tEmbarked, the port of embarkation, has 2 missing values.\n",
    "\t•\tCabin, which has significant missing data (687 values) and complex formatting, will require special treatment or exclusion.\n",
    "\t•\tTicket and Name are high-cardinality text fields and may not contribute directly without further feature engineering.\n",
    "\n",
    "Overall, this dataset requires preprocessing steps such as imputation of missing values, encoding categorical variables, and scaling numerical features before it is ready for training a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188191c9",
   "metadata": {},
   "source": [
    "Before applying any machine learning models, it’s crucial to clean and organize the dataset. The next code performs several essential preprocessing steps to prepare the Titanic dataset for training:\n",
    "\n",
    "1. Standardizing column names:\n",
    "\n",
    "The column names are converted to lowercase, stripped of leading/trailing whitespace, and spaces are replaced with underscores. This makes them easier to handle programmatically and avoids potential errors in later steps.\n",
    "\n",
    "2. Selecting relevant features:\n",
    "\n",
    "The dataset is reduced to a subset of columns that will be used in the model. These include:\n",
    "- Numerical predictors: age, sibsp, parch, fare\n",
    "- Categorical predictors: pclass, sex, embarked\n",
    "- Target variable: survived\n",
    "\n",
    "3.\tSplitting the dataset:\n",
    "\n",
    "The cleaned dataset is divided into training (80%) and testing (20%) sets using train_test_split. This separation is crucial to evaluate the model’s performance on unseen data and to avoid overfitting.\n",
    "\n",
    "4.\tKeeping a copy of the original data:\n",
    "\n",
    "Backups of the original training and testing sets are stored so we can always refer back to the unprocessed version during further transformations or analysis.\n",
    "    \n",
    "These steps set a solid foundation for data imputation, encoding, and modeling, ensuring reproducibility and cleaner downstream code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37799852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize columns names\n",
    "df_adjusted.columns = [col_name.strip().lower().replace(\" \",\"_\") for col_name in df_adjusted.columns]\n",
    "\n",
    "# Define predictors and targets\n",
    "predictors_num = ['age', 'sibsp', 'parch','fare']\n",
    "predictors_cat = ['pclass', 'sex', 'embarked']\n",
    "target = 'survived'\n",
    "df_adjusted = df_adjusted[predictors_num + predictors_cat + [target]]\n",
    "\n",
    "# Train/test split\n",
    "train_data, test_data= train_test_split(df_adjusted, test_size=0.2, random_state=42)\n",
    "train_data_original = train_data.copy()\n",
    "test_data_original = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a0840",
   "metadata": {},
   "source": [
    "\n",
    "At this stage, our dataset has already been split into training and testing sets. However, we still need to perform three key transformations to prepare the data for modeling:\n",
    "- Imputation: Filling in missing values (specifically in Age and Embarked).\n",
    "- Encoding: Converting categorical variables into dummy/indicator variables.\n",
    "- Normalization: Scaling numerical features to a standard range.\n",
    "\n",
    "Having explored the internal mechanisms behind these preprocessing techniques in previous notebooks, we now move on to applying scikit-learn’s built-in tools to carry out essential data transformations.\n",
    "\n",
    "It is crucial that we apply these transformations consistently:\n",
    "- We fit the imputers and scalers only on the training data.\n",
    "- We then apply the same parameters (learned from training) to transform the test data.\n",
    "\n",
    "This ensures that no information from the test set leaks into the training process, preserving the integrity of our model evaluation. We’ll start by creating custom imputers specifically for the Age and Embarked columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684726f",
   "metadata": {},
   "source": [
    "**Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca02f9",
   "metadata": {},
   "source": [
    "To address missing values in our dataset, we apply two distinct imputation strategies tailored to the characteristics of the variables:\n",
    "\n",
    "1. KNN Imputer (for Embarked)\n",
    "\n",
    "The Embarked column contains categorical data with a few missing entries. Instead of using a simple strategy like most frequent value, we opt for a more nuanced method: the K-Nearest Neighbors (KNN) imputer.\n",
    "\n",
    "This technique fills in missing values based on the values of the k-nearest complete rows, using a distance metric (often Euclidean for numerical features). In our context, the KNN imputer uses the similarity between rows (based on other features like Pclass, Sex, etc.) to infer the most appropriate value for Embarked.\n",
    "\n",
    "This strategy allows for data-aware imputations that consider the relationship between features, often resulting in better estimates than simpler approaches.\n",
    "\n",
    "2. Group-Based Imputer (for Age)\n",
    "\n",
    "The Age column is a continuous numerical feature with more missing entries and considerable variability. Using a constant mean or KNN may not be ideal, especially if Age depends on other variables like Pclass or Sex.\n",
    "\n",
    "We therefore define a custom imputer using a GroupByImputer class. It works as follows:\n",
    "- It groups rows using one or more specified columns (e.g., Pclass, Sex).\n",
    "- For each group, it calculates an aggregate value (e.g., the mean age).\n",
    "- Missing values are filled based on the group to which the row belongs.\n",
    "\n",
    "This approach provides context-sensitive imputations, preserving relationships between features and improving model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fbc141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupByImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_cols, target_col, agg='mean'):\n",
    "        self.group_cols = group_cols\n",
    "        self.target_col = target_col\n",
    "        self.agg = agg\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill_values_ = (\n",
    "            X.groupby(self.group_cols)[self.target_col]\n",
    "            .agg(self.agg)\n",
    "            .to_dict()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def get_fill_value(row):\n",
    "            key = tuple(row[col] for col in self.group_cols)\n",
    "            return self.fill_values_.get(key, X[self.target_col].mean())\n",
    "        \n",
    "        mask = X[self.target_col].isnull()\n",
    "        X.loc[mask, self.target_col] = X[mask].apply(get_fill_value, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31532a54",
   "metadata": {},
   "source": [
    "*Train dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f23b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the imputer we code before for getting ages considering agreggations in \"sex\" and \"pclass\"\n",
    "age_imputer = GroupByImputer(group_cols=['sex','pclass'], target_col='age', agg = 'mean')\n",
    "age_imputer.fit(train_data)\n",
    "train_data = age_imputer.transform(train_data)\n",
    "\n",
    "# Apply a knn imputer for \"embarked\" this is already available in sklearn modules\n",
    "# Input embarked\n",
    "col_to_inpute = 'embarked'\n",
    "le = LabelEncoder()\n",
    "not_nan_mask = train_data[col_to_inpute].notna()\n",
    "le.fit(train_data.loc[not_nan_mask, col_to_inpute])\n",
    "train_data.loc[not_nan_mask, col_to_inpute] = le.transform(train_data.loc[not_nan_mask, col_to_inpute])\n",
    "\n",
    "# Convert to float\n",
    "train_data[col_to_inpute] = train_data[col_to_inpute].astype(float)\n",
    "\n",
    "# Apply KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "columns = predictors_num + [col_to_inpute]\n",
    "knn_imputer.fit(train_data[columns])\n",
    "imputed = knn_imputer.transform(train_data[columns])\n",
    "\n",
    "# Replace the encoded column\n",
    "train_data[col_to_inpute] = imputed[:, columns.index(col_to_inpute)]\n",
    "\n",
    "# Decode back to original string labels\n",
    "train_data[col_to_inpute] = train_data[col_to_inpute].round().astype(int)\n",
    "train_data[col_to_inpute] = le.inverse_transform(train_data[col_to_inpute])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58592f7",
   "metadata": {},
   "source": [
    "*Test dataset* - We use the imputers fitted with the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61df406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the imputer we code before - We still using the one fitted in train dataset\n",
    "test_data = age_imputer.transform(test_data)\n",
    "\n",
    "# Apply a knn imputer for \"embarked\" this is already available in sklearn modules\n",
    "# Input embarked\n",
    "col_to_inpute = 'embarked'\n",
    "not_nan_mask = test_data[col_to_inpute].notna()\n",
    "test_data.loc[not_nan_mask, col_to_inpute] = le.transform(test_data.loc[not_nan_mask, col_to_inpute])\n",
    "\n",
    "# Convert to float\n",
    "test_data[col_to_inpute] = test_data[col_to_inpute].astype(float)\n",
    "\n",
    "# Apply KNN imputer\n",
    "columns = predictors_num + [col_to_inpute]\n",
    "imputed = knn_imputer.transform(test_data[columns])\n",
    "\n",
    "# Replace the encoded column\n",
    "test_data[col_to_inpute] = imputed[:, columns.index(col_to_inpute)]\n",
    "\n",
    "# Decode back to original string labels\n",
    "test_data[col_to_inpute] = test_data[col_to_inpute].round().astype(int)\n",
    "test_data[col_to_inpute] = le.inverse_transform(test_data[col_to_inpute])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4c9c5",
   "metadata": {},
   "source": [
    "**Encoding variables for categorical predictors (dummies variables)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd90f9e",
   "metadata": {},
   "source": [
    "One-hot encoding transforms each categorical variable into multiple binary (0/1) columns—one for each unique category. For example, the Sex variable with two possible values (male, female) would be transformed into two columns:\n",
    "- Sex_male: 1 if the passenger is male, 0 otherwise.\n",
    "- Sex_female: 1 if the passenger is female, 0 otherwise.\n",
    "\n",
    "This representation ensures that:\n",
    "- The model does not assume any ordinal relationship between categories.\n",
    "- Each category is treated independently by the algorithm.\n",
    "\n",
    "To avoid multicollinearity (where one variable is perfectly correlated with others), it’s common practice to drop one dummy column per categorical variable. This doesn’t cause any loss of information because the dropped category can always be inferred from the remaining ones.\n",
    "\n",
    "In our implementation, we won't drop a variable but **it's important for you to know that this could help**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557eb72",
   "metadata": {},
   "source": [
    "*Train dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433735cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/z7k3sy6x0l555p2rqjf6zvtr0000gn/T/ipykernel_16011/2462639932.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_data = train_data.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.get_dummies(train_data, columns=predictors_cat)\n",
    "train_data = train_data.replace({True: 1, False: 0})\n",
    "\n",
    "# Reordenar las columnas: target al final\n",
    "train_data = train_data[[c for c in train_data.columns if c != target] + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c7be8",
   "metadata": {},
   "source": [
    "*Test dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b34fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/z7k3sy6x0l555p2rqjf6zvtr0000gn/T/ipykernel_16011/2626425710.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_data = test_data.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "# Get dummies\n",
    "test_data = pd.get_dummies(test_data, columns=predictors_cat)\n",
    "test_data = test_data.replace({True: 1, False: 0})\n",
    "\n",
    "# Reordenar las columnas: target al final\n",
    "test_data = test_data[[c for c in test_data.columns if c != target] + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd620a",
   "metadata": {},
   "source": [
    "**Normalization for numerical variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f80a7",
   "metadata": {},
   "source": [
    "Normalization is a crucial preprocessing step when working with numerical features in machine learning models like logistic regression. Its purpose is to standardize the scale of features so that each has a mean of 0 and a standard deviation of 1 (when using StandardScaler). This helps gradient-based algorithms converge more efficiently and prevents features with larger numerical ranges from dominating the optimization process.\n",
    "\n",
    "In our case, we apply normalization only to continuous numerical variables such as:\n",
    "- age\n",
    "- sibsp\n",
    "- parch\n",
    "- fare\n",
    "\n",
    "These features can vary significantly in scale, so normalization ensures that the model treats them more equally during training.\n",
    "\n",
    "Important: Dummy variables (created from categorical features like sex, pclass, and embarked) should not be normalized. These binary indicators (0 or 1) represent category membership. Scaling them would distort their meaning and interfere with the model’s interpretation of category presence. Therefore, we exclude them from the normalization process.\n",
    "\n",
    "By carefully separating numerical and categorical features during preprocessing, we ensure that each transformation is applied only where it makes sense, maintaining data integrity and improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ad98e",
   "metadata": {},
   "source": [
    "*Train dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "821a8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to standardize\n",
    "cols_to_scale = predictors_num\n",
    "\n",
    "# Build transformer\n",
    "standar_scaler = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), cols_to_scale)\n",
    "    ],\n",
    "    remainder='passthrough'  # keep other columns (e.g. 'gender') untouched\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "standar_scaler.fit(train_data)\n",
    "data_scaled = standar_scaler.transform(train_data)\n",
    "\n",
    "# Get correct column order and names\n",
    "new_columns = cols_to_scale + [col for col in train_data.columns if col not in cols_to_scale]\n",
    "train_data = pd.DataFrame(data_scaled, columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc5deb",
   "metadata": {},
   "source": [
    "*Test dataset* - Apply the standard scaler fitted with the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e9f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization - We still using the one fitted in train\n",
    "data_scaled = standar_scaler.transform(test_data)\n",
    "\n",
    "# Get correct column order and names\n",
    "new_columns = cols_to_scale + [col for col in test_data.columns if col not in cols_to_scale]\n",
    "test_data = pd.DataFrame(data_scaled, columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e620c96",
   "metadata": {},
   "source": [
    "**Our final data**\n",
    "\n",
    "Finally we get our final X_train, y_train, X_test and y_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685d6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictors = [col for col in train_data.columns if col!='survived']\n",
    "final_target = 'survived'\n",
    "\n",
    "# Training data\n",
    "X_train = train_data[final_predictors]\n",
    "y_train = train_data[final_target]\n",
    "\n",
    "# Testing data\n",
    "X_test = test_data[final_predictors]\n",
    "y_test = test_data[final_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f4718",
   "metadata": {},
   "source": [
    "**Implementing Logistic Regression from Scratch**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f98fc",
   "metadata": {},
   "source": [
    "To deepen our understanding of how logistic regression works, we will now implement the model from scratch—without relying on external libraries like scikit-learn. This hands-on approach allows us to explore the internal mechanics of the algorithm, including how the model learns from data through gradient ascent and how the sigmoid function maps linear combinations into probabilities.\n",
    "\n",
    "The LogisticRegressionScratch class below encapsulates the full implementation of a binary logistic regression classifier. Its key features include:\n",
    "- Parameter Initialization: Random initialization of model coefficients (self.betas).\n",
    "- Training (fit method): Uses gradient ascent to maximize the log-likelihood of the data.\n",
    "- Prediction: Computes class probabilities using the logistic (sigmoid) function and returns binary predictions based on a threshold.\n",
    "- Gradient Calculation and Update: At each iteration, the model computes the partial derivatives of the log-likelihood function with respect to each coefficient—this is the gradient. Then, it updates the coefficients by taking a step in the direction of the gradient (gradient ascent), since we are maximizing the log-likelihood function. This process continues iteratively, gradually adjusting the coefficients to improve the model’s fit.\n",
    "- Probabilistic Objective Function: Tracks the model’s performance using the product of predicted probabilities (a form of the log-likelihood).\n",
    "\n",
    "This implementation reinforces essential machine learning concepts such as:\n",
    "- The role of gradients in optimization,\n",
    "- The probabilistic interpretation of logistic regression,\n",
    "\n",
    "In practice, for real-world applications we typically rely on highly optimized libraries like scikit-learn, but building this from the ground up offers critical intuition for what those libraries are doing internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e759e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    \"\"\" \n",
    "    A model to represent a logistic regression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" \n",
    "        Initialize the attributes needed\n",
    "        \"\"\"\n",
    "        self.betas = []\n",
    "        self.learning_rate = None\n",
    "        self.epochs = None\n",
    "        \n",
    "    def fit(self,\n",
    "            X: List[Vector], \n",
    "            y: Vector, \n",
    "            learning_rate: float = 0.001, \n",
    "            epochs: int = 1000) -> None:\n",
    "        \"\"\" \n",
    "        A method to train the model\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.betas = [random.random() for _ in range(len(X[0]) + 1)]\n",
    "        pbar = tqdm.tqdm(range(self.epochs), \"Training model\")\n",
    "        for epoch in pbar:\n",
    "            gradient = np.mean([self._gradient([1] + xi, yi) for xi, yi in zip(X,y)], axis=0)\n",
    "            new_betas = self._gradient_step(gradient)\n",
    "            self.betas = new_betas\n",
    "            prob = self._prob(X, y)\n",
    "            pbar.set_postfix({\"prob\": f\"{prob:.4f}\"})\n",
    "    \n",
    "    def _prob(self, X: List[Vector], y: Vector) -> float:\n",
    "        \"\"\" \n",
    "        Computes the function result we are maximizing\n",
    "        \"\"\"\n",
    "        probabilities = []\n",
    "        for x_i,y_i in zip(X, y):\n",
    "            probability = (self._logistic([1] + x_i)**y_i)*((1 - self._logistic([1] + x_i))**(1-y_i))\n",
    "            probabilities.append(probability)\n",
    "        \n",
    "        return np.mean(probabilities).item()\n",
    "    \n",
    "    def _gradient_step(self, gradient: Vector)-> Vector:\n",
    "        \"\"\" \n",
    "        Make a step in the direction to maximize the function\n",
    "        \"\"\"\n",
    "        return [self.betas[i] + (self.learning_rate*gradient[i]) for i in range(len(self.betas))]\n",
    "    \n",
    "    def predict(self, x: Vector, threshold: float = 0.5) -> float:\n",
    "        \"\"\" \n",
    "        Method to predict\n",
    "        \"\"\"\n",
    "        z = np.dot(self.betas, [1] + x)\n",
    "        return 1 if 1/(1 + math.exp(-z)) >= threshold else 0\n",
    "    \n",
    "    def _logistic(self, x: Vector) -> float:\n",
    "        \"\"\" \n",
    "        Return f(x) -> logistic function\n",
    "        \"\"\"\n",
    "        z = np.dot(self.betas, x)\n",
    "        return 1/(1 + math.exp(-z))\n",
    "    \n",
    "    def _logistic_derivative(self, x:Vector) -> float:\n",
    "        \"\"\" \n",
    "        Returns the derivative of the logistic function\n",
    "        \"\"\"\n",
    "        return self._logistic(x) * (1 - self._logistic(x))\n",
    "    \n",
    "    def _gradient(self, x:Vector, y:float) -> Vector:\n",
    "        \"\"\" \n",
    "        Return the gradient of a point\n",
    "        The objective function is the probability\n",
    "        \"\"\"\n",
    "        gradient = [\n",
    "             (y - self._logistic(x))*x[i] for i in range(len(self.betas))\n",
    "        ]\n",
    "        return gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdc1ac",
   "metadata": {},
   "source": [
    "To evaluate the performance of a classification model, especially in multi-class or imbalanced datasets, it is essential to go beyond basic accuracy. The following implementation provides a detailed computation of the confusion matrix and associated metrics such as precision, recall, and F1-score. It supports both binary and multi-class classification problems, with optional aggregation strategies for the latter.\n",
    "\n",
    "Let's code our metrics functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5b9a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our metrics report\n",
    "def cmatrix(y_true: Vector, y_pred: Vector) -> Dict[str, float]:\n",
    "    \"\"\" Get the confusion matrix of each label\n",
    "        Cols - Predicted\n",
    "        Rows - Actual\n",
    "    \"\"\"\n",
    "    real_labels = y_true\n",
    "    predicted_labels = y_pred\n",
    "    labels = sorted(list(set(real_labels + predicted_labels)), reverse=True)\n",
    "    cm = confusion_matrix(real_labels, predicted_labels, labels=labels)\n",
    "    \n",
    "    cm_detailed = defaultdict(dict)\n",
    "    for label_index in range(len(labels)):\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for row in range(len(labels)):\n",
    "            for col in range(len(labels)):\n",
    "                if row==label_index and col==label_index:\n",
    "                    tp += int(cm[row][col])\n",
    "                elif row==label_index and col!=label_index:\n",
    "                    fn += int(cm[row][col])\n",
    "                elif row!=label_index and col==label_index:\n",
    "                    fp += int(cm[row][col])\n",
    "                elif row!=label_index and col!=label_index:\n",
    "                    tn += int(cm[row][col])\n",
    "\n",
    "        cm_detailed[labels[label_index]]['tp'] = tp\n",
    "        cm_detailed[labels[label_index]]['tn'] = tn\n",
    "        cm_detailed[labels[label_index]]['fp'] = fp\n",
    "        cm_detailed[labels[label_index]]['fn'] = fn\n",
    "\n",
    "    return labels, cm, cm_detailed\n",
    "\n",
    "def metrics(y_true: Vector, y_pred: Vector, kind: Literal['micro','macro'] = 'micro') -> Dict[str, float]:\n",
    "    labels, cm, cm_detailed = cmatrix(y_true, y_pred)\n",
    "    # If just two labels we get the simpler confusion matrix and got metrics\n",
    "    if len(labels) == 2:\n",
    "        tp = cm_detailed[labels[0]]['tp']\n",
    "        fp = cm_detailed[labels[0]]['fp']\n",
    "        fn = cm_detailed[labels[0]]['fn']\n",
    "        tn = cm_detailed[labels[0]]['tn']\n",
    "        _accuracy = float(np.trace(cm)/np.sum(cm))\n",
    "        _precision = precision(tp, fp)\n",
    "        _recall = recall(tp, fn)\n",
    "        _f1_score = f1_score(tp, tn, fp, fn)\n",
    "\n",
    "        return {\n",
    "            \"labels\": labels,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"confusion_matrix_detailes\": cm_detailed,\n",
    "            \"accuracy\": _accuracy, \n",
    "            \"precision\": _precision, \n",
    "            \"recall\": _recall,\n",
    "            \"f1_score\": _f1_score\n",
    "        }\n",
    "    \n",
    "    # If multilabeled predictions we got micro or macro metrics\n",
    "    if len(labels) > 2:\n",
    "        _accuracy = float(np.trace(cm)/np.sum(cm))\n",
    "        if kind == 'micro':\n",
    "            tp = sum([cm_detailed[label]['tp'] for label in labels])\n",
    "            fp = sum([cm_detailed[label]['fp'] for label in labels])\n",
    "            fn = sum([cm_detailed[label]['fn'] for label in labels])\n",
    "            tn = sum([cm_detailed[label]['tn'] for label in labels])\n",
    "            _precision = precision(tp, fp)\n",
    "            _recall = recall(tp, fn)\n",
    "            _f1_score = f1_score(tp, tn, fp, fn)\n",
    "\n",
    "        elif kind == 'macro':\n",
    "            _precision = mean(\n",
    "                [\n",
    "                    precision(\n",
    "                        cm_detailed[label]['tp'],\n",
    "                        cm_detailed[label]['fp']\n",
    "                    )\n",
    "                    for label in labels\n",
    "                ]\n",
    "            \n",
    "            )\n",
    "\n",
    "            _recall = mean(\n",
    "                [\n",
    "                    recall(\n",
    "                        cm_detailed[label]['tp'],\n",
    "                        cm_detailed[label]['fn']\n",
    "                    )\n",
    "                    for label in labels\n",
    "                ]\n",
    "            \n",
    "            )\n",
    "\n",
    "            _f1_score = mean(\n",
    "                [\n",
    "                    f1_score(\n",
    "                        cm_detailed[label]['tp'],\n",
    "                        cm_detailed[label]['tn'],\n",
    "                        cm_detailed[label]['fp'],\n",
    "                        cm_detailed[label]['fn']\n",
    "                    )\n",
    "                    for label in labels\n",
    "                ]\n",
    "            \n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise AssertionError('Not a valid kind of metrics, use kind = \"micro\" or kind = \"macro\"')\n",
    "        \n",
    "        return {\n",
    "            \"labels\": labels,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"confusion_matrix_detailes\": cm_detailed,\n",
    "            \"accuracy\": _accuracy, \n",
    "            \"precision\": _precision, \n",
    "            \"recall\": _recall,\n",
    "            \"f1_score\": _f1_score\n",
    "        }\n",
    "\n",
    "def metrics(y_true: Vector, y_pred: Vector, kind: Literal['micro','macro'] = 'micro') -> Dict[str, float]:\n",
    "    labels, cm, cm_detailed = cmatrix(y_true, y_pred)\n",
    "    # If multilabeled predictions we got micro or macro metrics\n",
    "    if len(labels) > 0:\n",
    "        _accuracy = float(np.trace(cm)/np.sum(cm))\n",
    "        if kind == 'micro':\n",
    "            tp = sum([cm_detailed[label]['tp'] for label in labels])\n",
    "            fp = sum([cm_detailed[label]['fp'] for label in labels])\n",
    "            fn = sum([cm_detailed[label]['fn'] for label in labels])\n",
    "            tn = sum([cm_detailed[label]['tn'] for label in labels])\n",
    "            _precision = precision(tp, fp)\n",
    "            _recall = recall(tp, fn)\n",
    "            _f1_score = f1_score(tp, tn, fp, fn)\n",
    "\n",
    "        elif kind == 'macro':\n",
    "            _precision = mean(\n",
    "                [\n",
    "                    precision(\n",
    "                        cm_detailed[label]['tp'],\n",
    "                        cm_detailed[label]['fp']\n",
    "                    )\n",
    "                    for label in labels\n",
    "                ]\n",
    "            \n",
    "            )\n",
    "\n",
    "            _recall = mean(\n",
    "                [\n",
    "                    recall(\n",
    "                        cm_detailed[label]['tp'],\n",
    "                        cm_detailed[label]['fn']\n",
    "                    )\n",
    "                    for label in labels\n",
    "                ]\n",
    "            \n",
    "            )\n",
    "\n",
    "            _f1_score = mean(\n",
    "                [\n",
    "                    f1_score(\n",
    "                        cm_detailed[label]['tp'],\n",
    "                        cm_detailed[label]['tn'],\n",
    "                        cm_detailed[label]['fp'],\n",
    "                        cm_detailed[label]['fn']\n",
    "                    )\n",
    "                    for label in labels\n",
    "                ]\n",
    "            \n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise AssertionError('Not a valid kind of metrics, use kind = \"micro\" or kind = \"macro\"')\n",
    "        \n",
    "        return {\n",
    "            \"labels\": labels,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"confusion_matrix_detailes\": cm_detailed,\n",
    "            \"accuracy\": _accuracy, \n",
    "            \"precision\": _precision, \n",
    "            \"recall\": _recall,\n",
    "            \"f1_score\": _f1_score\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3423e2f",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c636a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 10000/10000 [03:51<00:00, 43.13it/s, prob=0.7149]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegressionScratch()\n",
    "model.fit(np.array(X_train).tolist(), np.array(y_train).tolist(), epochs=10000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14c426",
   "metadata": {},
   "source": [
    "**Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276787c",
   "metadata": {},
   "source": [
    "*Report in training data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "973a4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [model.predict(x) for x in np.array(X_train).tolist()]\n",
    "train_macro_metrics = metrics(np.array(y_train).tolist(), y_pred, kind='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae654120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Macro Metrics\n",
      "\n",
      "=== Classification Report ===\n",
      "Labels: [1.0, 0.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "  182  86\n",
      "  49  395\n",
      "\n",
      "Detailed Confusion Metrics per Class:\n",
      "  1.0          -> TP: 182, TN: 395, FP: 49, FN: 86\n",
      "  0.0          -> TP: 395, TN: 182, FP: 86, FN: 49\n",
      "\n",
      "Overall Metrics:\n",
      "  Accuracy : 0.8104\n",
      "  Precision: 0.8045\n",
      "  Recall   : 0.7844\n",
      "  F1 Score : 0.7918\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Macro Metrics\")\n",
    "print_classification_report(train_macro_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab9d5b",
   "metadata": {},
   "source": [
    "*Report in testing data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a062839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = [model.predict(x) for x in np.array(X_test).tolist()]\n",
    "test_macro_metrics = metrics(np.array(y_test).tolist(), y_pred, kind='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4927bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro Metrics\n",
      "\n",
      "=== Classification Report ===\n",
      "Labels: [1.0, 0.0]\n",
      "\n",
      "Confusion Matrix:\n",
      "  53  21\n",
      "  14  91\n",
      "\n",
      "Detailed Confusion Metrics per Class:\n",
      "  1.0          -> TP: 53, TN: 91, FP: 14, FN: 21\n",
      "  0.0          -> TP: 91, TN: 53, FP: 21, FN: 14\n",
      "\n",
      "Overall Metrics:\n",
      "  Accuracy : 0.8045\n",
      "  Precision: 0.8018\n",
      "  Recall   : 0.7914\n",
      "  F1 Score : 0.7952\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Macro Metrics\")\n",
    "print_classification_report(test_macro_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e1d49",
   "metadata": {},
   "source": [
    "The logistic regression model implemented from scratch demonstrated solid classification performance on the test dataset. With an accuracy of 80.45%, the model correctly predicted the target class in the majority of cases. The macro-averaged metrics indicate a balanced performance across both classes:\n",
    "- Precision: 80.18% – When the model predicts a positive case, it’s correct about 80% of the time.\n",
    "- Recall: 79.14% – The model correctly identifies around 79 out of every 100 actual positive cases.\n",
    "- F1 Score: 79.52% – This reflects a solid balance between precision and recall, indicating overall reliability.\n",
    "\n",
    "The confusion matrix shows a reasonable distribution of true positives and true negatives for both classes. However, there’s still room for improvement in reducing false negatives and false positives, particularly for class 1.0, which had 21 false negatives, indicating some difficulty in detecting positive cases.\n",
    "\n",
    "Now we will plot the results to make it clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1e5e442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to numpy arrays if needed\n",
    "y_true = np.array(y_test)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Create an array for the index (or sample number)\n",
    "indices = np.arange(len(y_true))\n",
    "\n",
    "# Define colors: green for correct, red for incorrect\n",
    "colors = ['green' if yt == yp else 'red' for yt, yp in zip(y_true, y_pred)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(indices, y_true, c=colors, marker='o', edgecolor='black', label='True Label')\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('True Labels: Green = Correct | Red = Incorrect')\n",
    "plt.yticks([0, 1])\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf3ba9",
   "metadata": {},
   "source": [
    "### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84edcf8b",
   "metadata": {},
   "source": [
    "In this notebook, we implemented logistic regression from scratch, gaining a deeper understanding of its mathematical foundation, particularly the use of the logistic function and gradient ascent to maximize the likelihood. Through manual implementation, we explored how model coefficients are iteratively updated to improve prediction accuracy.\n",
    "\n",
    "We also covered essential data preprocessing steps, including splitting data into training and testing sets, imputing missing values with tailored imputers, encoding categorical variables, and standardizing numerical features—highlighting the importance of applying transformations consistently between train and test datasets.\n",
    "\n",
    "Finally, we evaluated our model using detailed performance metrics(macro-averaged), which provided comprehensive insight into the classifier’s behavior on different classes. Visualization of prediction accuracy further reinforced understanding of model performance.\n",
    "\n",
    "This hands-on approach not only reinforces theoretical concepts but also equips us with practical skills to build, evaluate, and refine logistic regression models in real-world scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
