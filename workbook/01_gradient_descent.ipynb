{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3b3b8e",
   "metadata": {},
   "source": [
    "## HOW DOES GRADIENT DESCENT WORKS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abd8299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used through this explanation\n",
    "import random\n",
    "from scratch.gradient_descent import gradient_step\n",
    "from scratch.complex_typing import Vector\n",
    "from scratch.linear_algebra import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48f0e9",
   "metadata": {},
   "source": [
    "Imagine we have a sum of squares function\n",
    "\n",
    "$$\n",
    "f(x, y, z) = x^2 + y^2 + z^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671b544",
   "metadata": {},
   "source": [
    "We want to compute the **gradient** of the function to understand how it changes with respect to each variable. This is essential for gradient-based optimization, where the goal is to find the point that minimizes the function.\n",
    "\n",
    "For example, if we have the function:\n",
    "\n",
    "its partial derivatives are:\n",
    "- $\\frac{\\partial f}{\\partial x} = 2x$\n",
    "- $\\frac{\\partial f}{\\partial y} = 2y$\n",
    "- $\\frac{\\partial f}{\\partial z} = 2z$\n",
    "\n",
    "These represent the slope of the function along each axis. The gradient vector combines them:\n",
    "\n",
    "$$\n",
    "\\nabla f(x, y, z) = \\left( 2x,\\ 2y,\\ 2z \\right)\n",
    "$$\n",
    "\n",
    "This gradient points in the direction of steepest increase. To minimize the function, we move in the opposite direction — toward the point where the gradient is zero, which in this case is the origin: $(0, 0, 0)$.\n",
    "\n",
    "Let’s define a function that returns this gradient vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c43cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_squares_gradient(v: Vector):\n",
    "    # Gradient for a sum of squares function\n",
    "    return [2*v_i for v_i in v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e782059",
   "metadata": {},
   "source": [
    "Now we have to take a random point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10239595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.2312768532071985, -9.861394979835412, -2.991835185564808]\n"
     ]
    }
   ],
   "source": [
    "v = [random.uniform(-10,10) for i in range(3)]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be98077",
   "metadata": {},
   "source": [
    "Then we do the magic, we are going to iterate many times:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c124fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs:0 -> [6.2312768532071985, -9.861394979835412, -2.991835185564808]\n",
      "obs:1 -> [6.106651316143054, -9.664167080238704, -2.931998481853512]\n",
      "obs:2 -> [5.984518289820193, -9.47088373863393, -2.873358512216442]\n",
      "obs:3 -> [5.864827924023789, -9.28146606386125, -2.815891341972113]\n",
      "obs:4 -> [5.747531365543313, -9.095836742584025, -2.759573515132671]\n",
      "obs:5 -> [5.632580738232447, -8.913920007732344, -2.7043820448300173]\n",
      "obs:495 -> [0.00028280332742456005, -0.0004475543903830732, -0.00013578291665023996]\n",
      "obs:496 -> [0.00027714726087606884, -0.00043860330257541175, -0.00013306725831723517]\n",
      "obs:497 -> [0.0002716043156585475, -0.00042983123652390353, -0.00013040591315089048]\n",
      "obs:498 -> [0.0002661722293453765, -0.0004212346117934255, -0.00012779779488787267]\n",
      "obs:499 -> [0.000260848784758469, -0.000412809919557557, -0.0001252418389901152]\n",
      "obs:500 -> [0.00025563180906329957, -0.0004045537211664058, -0.0001227370022103129]\n"
     ]
    }
   ],
   "source": [
    "n_obs = 0\n",
    "print(f\"obs:{n_obs} -> {v}\")\n",
    "for epoch in range(500):\n",
    "    grad = sum_of_squares_gradient(v)\n",
    "    v = gradient_step(v, grad, -0.01)\n",
    "    n_obs += 1\n",
    "    if n_obs <=5 or n_obs>=495:\n",
    "        print(f\"obs:{n_obs} -> {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149d831",
   "metadata": {},
   "source": [
    "Now we should be able to see that v is close to [0, 0, 0] were it finds it's minimun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
